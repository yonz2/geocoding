{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MangaGAN2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonz2/geocoding/blob/master/MangaGAN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCmBCfnQWKZU"
      },
      "source": [
        "!pip list | grep tensorflow\n",
        "!pip install ffmpeg-python"
      ],
      "id": "jCmBCfnQWKZU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKjs24EjZDaA"
      },
      "source": [
        "print(\"Start!\")\n",
        "\n",
        "# Make sure the GDrive where the Images are stored is mounted....\n",
        "import os.path\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/gdrive/MyDrive'):\n",
        "   drive.mount('/content/gdrive')\n",
        "   \n",
        "print(\"Done!\")"
      ],
      "id": "AKjs24EjZDaA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTmKeCyt9YiB"
      },
      "source": [
        "print(\"Start!\")\n",
        "\n",
        "# Import various support modules\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import tqdm\n",
        "import glob\n",
        "import scipy\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import ffmpeg\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "\n",
        "# Import required tensforflow and keras modules\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.core import Flatten, Dropout\n",
        "from keras.layers import Input, merge\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import load_model, save_model\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "dTmKeCyt9YiB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjWyim7-9vof"
      },
      "source": [
        "print(\"Start!\")\n",
        "\n",
        "from tensorflow.keras.layers import InputSpec, Layer\n",
        "\n",
        "#https://github.com/WeidiXie/New_Layers-Keras-Tensorflow/blob/master/src/subpix_upsampling.py\n",
        "#OR \n",
        "#BELOW  (https://github.com/farizrahman4u/keras-contrib/blob/a7520c8f520bb5643ff9a62d1b3532fe72ab7283/keras_contrib/layers/convolutional.py)\n",
        "class SubPixelUpscaling(Layer):\n",
        "\n",
        "    def __init__(self, scale_factor=2, data_format=None, **kwargs):\n",
        "        super(SubPixelUpscaling, self).__init__(**kwargs)\n",
        "\n",
        "        self.scale_factor = scale_factor\n",
        "        self.data_format = normalize_data_format(data_format)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        pass\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        y = K.depth_to_space(x, self.scale_factor, self.data_format)\n",
        "        return y\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            b, k, r, c = input_shape\n",
        "            return (b, k // (self.scale_factor ** 2), r * self.scale_factor, c * self.scale_factor)\n",
        "        else:\n",
        "            b, r, c, k = input_shape\n",
        "            return (b, r * self.scale_factor, c * self.scale_factor, k // (self.scale_factor ** 2))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'scale_factor': self.scale_factor,\n",
        "                  'data_format': self.data_format}\n",
        "        base_config = super(SubPixelUpscaling, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "VjWyim7-9vof",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndRiv5pWikkk"
      },
      "source": [
        "print(\"Start!\")\n",
        "\n",
        "def normalize_data_format(value):\n",
        "    if value is None:\n",
        "        value = K.image_data_format()\n",
        "    data_format = value.lower()\n",
        "    if data_format not in {'channels_first', 'channels_last'}:\n",
        "        raise ValueError('The `data_format` argument must be one of '\n",
        "                         '\"channels_first\", \"channels_last\". Received: ' +\n",
        "                         str(value))\n",
        "    return data_format\n",
        "    \n",
        "print(\"Done!\") "
      ],
      "id": "ndRiv5pWikkk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7adefd4"
      },
      "source": [
        "print(\"Start!\")\n",
        "\n",
        "def get_gen_normal(noise_shape):\n",
        "  noise_shape = noise_shape\n",
        "\n",
        "  kernel_init = 'glorot_uniform'\n",
        "\n",
        "  gen_input = Input(shape = noise_shape)\n",
        "  generator = Conv2DTranspose(filters = 512, kernel_size = (4,4), strides = (1,1), padding = \"valid\", data_format = \"channels_last\", kernel_initializer = kernel_init)(gen_input)\n",
        "  generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "  generator = LeakyReLU(0.2)(generator)\n",
        "      \n",
        "  generator = Conv2DTranspose(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "  generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "  generator = LeakyReLU(0.2)(generator)\n",
        "\n",
        "  generator = Conv2DTranspose(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "  generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "  generator = LeakyReLU(0.2)(generator)\n",
        "\n",
        "  generator = Conv2DTranspose(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "  generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "  generator = LeakyReLU(0.2)(generator)\n",
        "\n",
        "  generator = Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "  generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "  generator = LeakyReLU(0.2)(generator)\n",
        "\n",
        "  generator = Conv2DTranspose(filters = 3, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "  generator = Activation('tanh')(generator)\n",
        "      \n",
        "  gen_opt = Adam(learning_rate=0.00015, beta_1=0.5)\n",
        "  # Note: Change \"input\" to \"inputs\" and \"output\" to \"outputs\"\n",
        "  generator_model = Model(inputs = gen_input, outputs = generator)\n",
        "  generator_model.compile(loss='binary_crossentropy', optimizer=gen_opt, metrics=['accuracy'])\n",
        "  generator_model.summary()\n",
        "\n",
        "  return generator_model\n",
        "\n",
        "    \n",
        "print(\"Done!\")"
      ],
      "id": "a7adefd4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a611ec6"
      },
      "source": [
        "print(\"Start!\")\n",
        "\n",
        "def get_disc_normal(image_shape=(64,64,3)):\n",
        "  image_shape = image_shape\n",
        "\n",
        "  dropout_prob = 0.4\n",
        "  kernel_init = 'glorot_uniform'\n",
        "  dis_input = Input(shape = image_shape)\n",
        "  discriminator = Conv2D(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(dis_input)\n",
        "  discriminator = LeakyReLU(0.2)(discriminator)\n",
        "  discriminator = Conv2D(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
        "  discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
        "  discriminator = LeakyReLU(0.2)(discriminator)\n",
        "\n",
        "  discriminator = Conv2D(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
        "  discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
        "  discriminator = LeakyReLU(0.2)(discriminator)\n",
        "\n",
        "  discriminator = Conv2D(filters = 512, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
        "  discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
        "  discriminator = LeakyReLU(0.2)(discriminator)\n",
        "\n",
        "  discriminator = Flatten()(discriminator)\n",
        "\n",
        "  discriminator = Dense(1)(discriminator)\n",
        "  discriminator = Activation('sigmoid')(discriminator)\n",
        "  #also try the SGD optimiser, might work better for a few learning rates.\n",
        "  dis_opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "  # Note: Change \"input\" to \"inputs\" and \"output\" to \"outputs\"\n",
        "  discriminator_model = Model(inputs = dis_input, outputs = discriminator)\n",
        "  discriminator_model.compile(loss='binary_crossentropy', optimizer=dis_opt, metrics=['accuracy'])\n",
        "  discriminator_model.summary()\n",
        "  return discriminator_model\n",
        "print(\"Done!\")\n"
      ],
      "id": "7a611ec6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efc96890"
      },
      "source": [
        "print(\"Start!\")\n",
        "\n",
        "def norm_img(img):\n",
        "    img = (img / 127.5) - 1\n",
        "    #image normalisation to keep values between -1 and 1 for stability\n",
        "    return img\n",
        "\n",
        "def denorm_img(img):\n",
        "    #for output\n",
        "    img = (img + 1) * 127.5\n",
        "    return img.astype(np.uint8) \n",
        "\n",
        "\n",
        "def sample_from_dataset(batch_size, image_shape, data_dir=None, data = None):\n",
        "    sample_dim = (batch_size,) + image_shape\n",
        "    sample = np.empty(sample_dim, dtype=np.float32)\n",
        "    all_data_dirlist = list(glob.glob(data_dir))\n",
        "    sample_imgs_paths = np.random.choice(all_data_dirlist,batch_size)\n",
        "    for index,img_filename in enumerate(sample_imgs_paths):\n",
        "        image = Image.open(img_filename)\n",
        "        image = image.resize(image_shape[:-1])\n",
        "        image = image.convert('RGB')\n",
        "        image = np.asarray(image)\n",
        "        image = norm_img(image)\n",
        "        sample[index,...] = image\n",
        "    return sample\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "efc96890",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "025ddcc2"
      },
      "source": [
        "print(\"Start!\")\n",
        "\n",
        "def gen_noise(batch_size, noise_shape):\n",
        "    #input noise for the generator should follow a probability distribution, like in this case, the normal distributon.\n",
        "    return np.random.normal(0, 1, size=(batch_size,)+noise_shape)\n",
        "\n",
        "def generate_images(generator, save_dir):\n",
        "    \n",
        "    noise = gen_noise(batch_size,noise_shape)\n",
        "    fake_data_X = generator.predict(noise)\n",
        "    print(\"Displaying generated images\")\n",
        "    plt.figure(figsize=(4,4))\n",
        "    gs1 = gridspec.GridSpec(4, 4)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "    rand_indices = np.random.choice(fake_data_X.shape[0],16,replace=False)\n",
        "    for i in range(16):\n",
        "        #plt.subplot(4, 4, i+1)\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        rand_index = rand_indices[i]\n",
        "        image = fake_data_X[rand_index, :,:,:]\n",
        "        fig = plt.imshow(denorm_img(image))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_dir+str(time.time())+\"_GENimage.png\",bbox_inches='tight',pad_inches=0)\n",
        "    # plt.show()\n",
        "    plt.close()\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "025ddcc2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClsFSI2XMRqQ"
      },
      "source": [
        "print(\"Start!\")\n",
        "# Define some helper methode to handle files from GDrive\n",
        "def get_from_gdrive_unzip(gdrive_zip_file_path): \n",
        "  # copy a ZIP File from Gdrive and unzipp it\n",
        "\n",
        "  dest_dir_path = '/content/datadir'\n",
        "  # Clean up before re-importing the data\n",
        "  if  os.path.exists(dest_dir_path):\n",
        "    !rm -R -f {dest_dir_path}\n",
        "  !mkdir {dest_dir_path}\n",
        "\n",
        "  data_file_dest_name = '/content/' + os.path.basename(gdrive_zip_file_path)\n",
        "  if os.path.exists(data_file_dest_name):\n",
        "    !rm -f {data_file_dest_name}\n",
        "  !cp {gdrive_zip_file_path} {data_file_dest_name}\n",
        "\n",
        "  !unzip -qq {data_file_dest_name} -d {dest_dir_path}\n",
        "\n",
        "  return dest_dir_path\n",
        "#\n",
        "\n",
        "def send_to_gdrive(source_path, gdrive_path, zipit=True):\n",
        "  # Zip the generated output files and copy back to GDrive\n",
        "\n",
        "  if zipit:\n",
        "    # First ZIP the Output Images\n",
        "    output_base = os.path.basename(source_path)\n",
        "    temp_zip_path = '/content/' + output_base + '.zip'\n",
        "    if  os.path.exists(temp_zip_path):\n",
        "      !rm -f {temp_zip_path}\n",
        "    !zip -q {temp_zip_path} {source_path} \n",
        "    !cp {temp_zip_path} {gdrive_path}\n",
        "  else:\n",
        "    # Copy the Models and Movie files as well\n",
        "    !cp -r {source_path}  {gdrive_path}\n",
        "  \n",
        "  return gdrive_path\n",
        "\n",
        "\n",
        "def gen_movie(image_dir, output_dir):\n",
        "  # Create a video from the generated output files  \n",
        "  date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "  video_stream = ffmpeg.input(image_dir +'*.png', pattern_type='glob', framerate=25)\n",
        "  video_stream = ffmpeg.output(video_stream, output_dir + 'output_' + date_time + '.mp4')\n",
        "  ffmpeg.run(video_stream)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "ClsFSI2XMRqQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0142098"
      },
      "source": [
        "print(\"Start!\")\n",
        "\n",
        "def save_img_batch(img_batch,img_save_dir):\n",
        "    plt.figure(figsize=(4,4))\n",
        "    gs1 = gridspec.GridSpec(4, 4)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "    rand_indices = np.random.choice(img_batch.shape[0],16,replace=False)\n",
        "    for i in range(16):\n",
        "        #plt.subplot(4, 4, i+1)\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        rand_index = rand_indices[i]\n",
        "        image = img_batch[rand_index, :,:,:]\n",
        "        fig = plt.imshow(denorm_img(image))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(img_save_dir,bbox_inches='tight',pad_inches=0)\n",
        "    #plt.show()\n",
        "    plt.close()   \n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "a0142098",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GllwlB8r-yrz"
      },
      "source": [
        "print(\"Start Setting up some basic parameters\")\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "noise_shape = (1,1,100)\n",
        "num_steps = 10000\n",
        "batch_size =  64\n",
        "image_shape = None\n",
        "save_model = True\n",
        "image_shape = (64,64,3)\n",
        "\n",
        "print(\"Fetch the training data from GDrive\")\n",
        "\n",
        "get_from_gdrive_unzip('/content/gdrive/MyDrive/Manga-GAN-master.zip') \n",
        "\n",
        "data_dir =  \"/content/datadir/Manga-GAN-master/data/*.png\"\n",
        "img_save_dir = \"/content/datadir/Manga-GAN/output_images/\"\n",
        "log_dir = \"/content/datadir/Manga-GAN/logs/\"\n",
        "save_model_dir = \"/content/datadir/Manga-GAN/models/\"\n",
        "movie_dir = \"/content/datadir/Manga-GAN/movies/\"\n",
        "\n",
        "gdrive_results = '/content/gdrive/MyDrive/MangaGAN_Results'\n",
        "\n",
        "# Make sure the directories exists:\n",
        "!mkdir -p {img_save_dir}\n",
        "!mkdir -p {log_dir}\n",
        "!mkdir -p {save_model_dir}\n",
        "!mkdir -p {movie_dir}\n",
        "\n",
        "# Check for a GPU. If found set the device for Tensorflow to use it\n",
        "%tensorflow_version 2.x\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices())\n",
        "print(\" \")\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  device_name = '/cpu:0'\n",
        "\n",
        "print('Tensorflow will use the ' + device_name + ' device for the heavy work')\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "GllwlB8r-yrz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SsZ2hx-SUUw"
      },
      "source": [
        "\n"
      ],
      "id": "8SsZ2hx-SUUw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9037376"
      },
      "source": [
        "print(\"Start the real work...\")\n",
        "\n",
        "np.random.seed(7919) # Was 1337\n",
        "\n",
        "with tf.device(device_name):\n",
        "  discriminator = get_disc_normal(image_shape)\n",
        "  generator = get_gen_normal(noise_shape)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "a9037376",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d74304a6"
      },
      "source": [
        "print(\"Start...\")\n",
        "with tf.device(device_name):\n",
        "  discriminator.trainable = False\n",
        "\n",
        "  opt = Adam(learning_rate=0.00015, beta_1=0.5) \n",
        "  gen_inp = Input(shape=noise_shape)\n",
        "  GAN_inp = generator(gen_inp)\n",
        "  GAN_opt = discriminator(GAN_inp)\n",
        "  gan = Model(inputs = gen_inp, outputs = GAN_opt)\n",
        "  gan.compile(loss = 'binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
        "  gan.summary()\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "d74304a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a96edf1d"
      },
      "source": [
        "print(\"Start...\")\n",
        "\n",
        "with tf.device(device_name):\n",
        "  avg_disc_fake_loss = deque([0], maxlen=250)     \n",
        "  avg_disc_real_loss = deque([0], maxlen=250)\n",
        "  avg_GAN_loss = deque([0], maxlen=250)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "a96edf1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6534e84a"
      },
      "source": [
        "print(\"Start....\")\n",
        "\n",
        "begin_time = time.time()\n",
        "step_begin_time = time.time()\n",
        "with tf.device(device_name):\n",
        "  with open(log_dir+\"training_log.txt\", \"w\") as text_file:\n",
        "    for step in range(num_steps): \n",
        "        \n",
        "        real_data_X = sample_from_dataset(batch_size, image_shape, data_dir = data_dir)\n",
        "\n",
        "        noise = gen_noise(batch_size,noise_shape)\n",
        "        \n",
        "        fake_data_X = generator.predict(noise)\n",
        "        \n",
        "        if (step % 10) == 0:\n",
        "            step_num = str(step).zfill(5)\n",
        "            save_img_batch(fake_data_X,img_save_dir+step_num+\"_image.png\")\n",
        "\n",
        "        #concatenate real and fake data samples    \n",
        "        data_X = np.concatenate([real_data_X,fake_data_X])\n",
        "        #add noise to the label inputs\n",
        "        real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "        \n",
        "        \n",
        "        fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
        "        \n",
        "        data_Y = np.concatenate((real_data_Y,fake_data_Y))\n",
        "            \n",
        "        discriminator.trainable = True\n",
        "        generator.trainable = False\n",
        "        #training the discriminator on real and fake data can be done together, i.e., \n",
        "        #on the data_x and data_y, OR it can be done \n",
        "        #one by one as performed below. This is the safer choice and gives better results \n",
        "        #as compared to combining the real and generated samples.\n",
        "        dis_metrics_real = discriminator.train_on_batch(real_data_X,real_data_Y)  \n",
        "        dis_metrics_fake = discriminator.train_on_batch(fake_data_X,fake_data_Y)   \n",
        "        \n",
        "        avg_disc_fake_loss.append(dis_metrics_fake[0])\n",
        "        avg_disc_real_loss.append(dis_metrics_real[0])\n",
        "        \n",
        "        generator.trainable = True\n",
        "\n",
        "        GAN_X = gen_noise(batch_size,noise_shape)\n",
        "\n",
        "        GAN_Y = real_data_Y\n",
        "        \n",
        "        discriminator.trainable = False\n",
        "        \n",
        "        gan_metrics = gan.train_on_batch(GAN_X,GAN_Y)\n",
        "        \n",
        "        text_file.write(\"Step: %d Disc: real loss: %f fake loss: %f GAN loss: %f\\n\" % (step, dis_metrics_real[0], dis_metrics_fake[0],gan_metrics[0]))\n",
        "\n",
        "        if (step > 0) and (step % 10) == 0:\n",
        "          end_time = time.time()\n",
        "          diff_time = int(end_time - begin_time) / 60\n",
        "          step_diff_time = int(end_time - step_begin_time) \n",
        "          print(\"Steps %d completed. Elapsed time: %s seconds. Total elapsed time: %s minutes.\" % (step, step_diff_time, diff_time))\n",
        "          step_begin_time = time.time()\n",
        "\n",
        "        if (step > 0) and (step % 1000) == 0:\n",
        "            print(\"-----------------------------------------------------------------\")\n",
        "            print(\"Average Disc_fake loss: %f\" % (np.mean(avg_disc_fake_loss)))    \n",
        "            print(\"Average Disc_real loss: %f\" % (np.mean(avg_disc_real_loss)))    \n",
        "            print(\"Average GAN loss: %f\" % (np.mean(avg_GAN_loss)))\n",
        "            print(\"-----------------------------------------------------------------\")\n",
        "            discriminator.trainable = True\n",
        "            generator.trainable = True\n",
        "            step_num = str(step).zfill(5)\n",
        "            generator.save(save_model_dir+step_num+\"_GENERATOR_weights_and_arch.hdf5\")\n",
        "            discriminator.save(save_model_dir+step_num+\"_DISCRIMINATOR_weights_and_arch.hdf5\")\n",
        "            gen_movie(img_save_dir,movie_dir)\n",
        "            gpu_info = !nvidia-smi\n",
        "            gpu_info = '\\n'.join(gpu_info)\n",
        "            print(gpu_info)\n",
        "        # End For\n",
        "      # End With (Open file)\n",
        "    # End With (tf.device)\n",
        "# Save the last image\n",
        "step_num = str(step).zfill(5)\n",
        "save_img_batch(fake_data_X,img_save_dir+step_num+\"_image.png\")\n",
        "          \n",
        "print(\"Done!\")"
      ],
      "id": "6534e84a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjRWRrYtoF1h"
      },
      "source": [
        "print(\"Start....\")\n",
        "\n",
        "print(\"Save the Models for re-use\")\n",
        "with tf.device(device_name):\n",
        "  discriminator.trainable = True\n",
        "  generator.trainable = True\n",
        "  generator.save(save_model_dir+\"GENERATOR_weights_and_arch.hdf5\")\n",
        "  discriminator.save(save_model_dir+\"DISCRIMINATOR_weights_and_arch.hdf5\")\n",
        "gen_movie(img_save_dir,movie_dir)\n",
        "\n",
        "\n",
        "send_to_gdrive(img_save_dir, gdrive_results, zipit=True)\n",
        "send_to_gdrive(save_model_dir, gdrive_results, zipit=False)\n",
        "send_to_gdrive(log_dir, gdrive_results, zipit=False)\n",
        "send_to_gdrive(movie_dir, gdrive_results, zipit=False)\n",
        "\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "RjRWRrYtoF1h",
      "execution_count": null,
      "outputs": []
    }
  ]
}